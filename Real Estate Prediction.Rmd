---
output:
  html_document:
  pdf_document:
    keep_tex: yes
    latex_engine: xelatex
editor_options:
  chunk_output_type: console
---

```{r global-options, include=FALSE}
knitr::opts_chunk$set(warning=FALSE)
```
```{r, setup, include=FALSE}
knitr::opts_knit$set(root.dir ="~/RLectureData", echo=TRUE)
```

# Portfolio
### Question
> `Reyeme Affiare`는 Boston에서 여러 시간에 걸쳐 좋은 집을 구하고자 하였고 드디어 괜찮은 집을 찾은듯 하다. 하지만 어느정도 가격에 이 집을 구매하는것이 좋을지 확신이 없다. 어느 가격으로 `236 Ellery Street Cambridge` 의 집을 구매하는것이 좋을까 ?

### 1. 데이터 확인
#### 모든 분석은 R을 통해 진행된다. `Reyeme Affiare`이 힘들게 찾아낸 `236 Ellery Street Cambridge`의 Sweet Home에 대한 정보는 다음과 같다. 

변수명|값
:---:|:---
__Rooms__|5
__Bedroom__|2
__Bath__|1
__Location__|M
__Interior Space__|1040
__Monthly Condominium Fee__|$175
__Annual Property Taxes__|$1121
__Price__|$169000
__Put on Market__|1994-05-04

> 해당 지역 거래가격 데이터의 간단한 `EDA` 는 다음과 같다

```{r}
rey = read.csv('~/RLectureData/leyme.csv', header=T)  
attributes(rey)

```

> 데이터의 변수 중 `address`, `areacode`는 `area`와 중복되기에 삭제, `Unit`의 경우 필요한 변수가 아니기에 삭제, `First offer`는 궁금한 변수가 아니기에 위 3가지의 변수는 삭제를 실시. 


```{r}
rey_del=rey[-c(1,2,4,8)]
names(rey_del)

```
```{r}
str(rey_del)
dim(rey_del)
head(rey_del)
table(is.na(rey_del))
```

> 데이터의 숫자는 `456`, 변수의 숫자는 `13`이다. 결측치는 관찰되지 않으며 변수들 중 `Area`, `Rent Control`, `Days`변수의 경우 `Dummy Variable`처리를 하여 살펴볼 필요가 보인다. 


### 2. 다중회귀분석
#### 2.1 모델 선택
#### 먼저 모든 변수를 고려한 다중회귀분석을 실시해본다.  그전 `CloseDate`변수의 경우 연도별로 변수를 바꾸어 준 후 분석을 실시해본다.  

```{r}
year = as.Date(rey_del$CloseDate, "%m/%d/%Y")
library(lubridate)
year1 = year[c(1:456)]+years(1900)
rey_del$CloseDate=year1
year2 = substr(as.character(rey_del$CloseDate, "%Y-%m-%d"), 1,4)
rey_del_cbind=cbind(rey_del, year2)
```


>`closedate`를 기준으로 날짜 변환을 하였으나 원데이터 상 `91`, `93`등으로 년도가 축소되어 있었음으로 `1900`을 추가하여 원래 년도로 맞추어 주었다. 그 후 `year`만을 추출하여 현재 데이터에 추가해주었다. 



```{r}
library(car)
model1 = lm(data=rey_del_cbind, SalePrice ~ Area+FirstPrice+LastPrice+Days+Interior+Bed+Bath+Rooms+ year2)
summary(model1)
vif(model1)
```

> 먼저 전체 모델을 해본 결과 `adjusted r-squared`가 `0.992`로 매우 높게 나왔고 `AreaE`, `Areak`, `AreaN`, `FirstPrice`, `LastPrice`가 유의미하게 나오게 되었다. 하지만 이 값들이 유효하다고 보기는 어렵다. 왜냐하면 현재 우리가 구하고자 하는 지역은 `M`지역이다. 하지만 타 지역이 유효하게 도출되었고 `FirstPrice`와 `LastPrice`는 당연히 큰 공선성이 존재하리라 판단되기 때문이다. 따라서 `FirstPrice`와 `LastPrice`를 제외한 나머지 변수들을 이용해 모델 선택을 진행 후 최적 모델에 대해서 살펴볼 예정이다. 


```{r}
library(MASS)
start.model = lm(data=rey_del_cbind, SalePrice ~ Area)
stepAIC(start.model, scope=list(upper=~Area+year2+Days+Interior+Condo+Tax+RC+Bed+Bath+Rooms, lower=~Area), direction='both')

```


>`StepAIC` 함수를 활용하여 `AIC` 값을 고려한 결과 `SalePrice = Area + Tax + Interior + condo + year2 + RC + Days` 모델이 `9589.53`으로 가장 낮은 AIC값을 보였다. 따라서 해당 모델을 기준으로 `OLS`의 `Classical Assumption`을 살펴보려 한다


#### 2.2 Classical Assumption
#### `OLS`의 `고전 가정`은 다음과 같다. 
가정|요약|설명
:---:|:---|:---
__가정1__|모형구성에 대한 가정|가정한 회귀모형이 맞는 모형|
__가정2__|측정오차에 대한 가정|종속변수인 Y에 대한 측정오차로 구분되는 오차의 평균은 0이다
__가정3__|정규성 가정|측정오차는 정규분포를 따른다  
__가정4__|등분산성 가정|측정오차에 대한 분산은 Y가 어떠한 수준의 값을 가져도 일정한 표준편차를 갖는다. 
__가정5__|독립성에 대한 가정| 측정오차는 독립적으로 관측된다

```{r}
library(gridExtra)
library(ggplot2)
library(ggpubr)
model_AIC=lm(data=rey_del_cbind, SalePrice~Area + Tax + Interior + Condo + year2 + RC + Days + Bed + Bath + Rooms)
p1 = ggplot(model_AIC, aes(x=model_AIC$residuals, y=..density..)) +     geom_histogram(fill='blue', colour='white')+
  geom_density(fill=NA, colour=NA)+
  geom_line(stat="density")+
  ggtitle('Histogram + Kernal Density Curve Residual')

p2 = ggplot(model_AIC, aes(x=predict(model_AIC), y=resid(model_AIC))) +
  geom_point(colour="red")+
  ggtitle('Scatter plot Residuals')

p3 = ggplot(model_AIC, aes(sample=resid(model_AIC))) + 
  stat_qq()
  
grid.arrange(p1, p3, p2, ncol=3)

shapiro.test(resid(model_AIC))
library(car)
ncvTest(model_AIC)

```

> plot상으로 `정규성 가정`에 문제가 있는듯 보인다. 추가로 잔차의 산점도에서 문제가 있어 보인다. `shapiro test`결과 `정규성`에 문제가 발생하였고 `Breusch-Pagan Test` 결과에 따라 이분산성이 나타나는것으로 보인다. 여기서 우리는  1. $Y$ 변환 등의 방법을 고려하거나 2. `GLS`, `WLS`등을 활용하여 분산을 정상화 시키는 방법을 고려할 수 있다.본 연구에서는 $Y$ 변환을 고려해 보겠다. 


#### 2.4 $Y$ 변환

잔차와 Y관계|해결방안
:---|:---
1. 잔차의 분산이 $Y$의값과 비례하는 경우|$\sqrt{Y}$변환 사용
2. 잔차의 표준편차가 $Y$의 값과 비례하는 경우|$\log(Y)$변환 사용
3. 잔차의 표준편차가 $Y^2$의 값과 비례하는 경우|$1/Y$변환 사용

```{r}
library(Metrics)
p_resid1=ggplot(model_AIC, aes(x=rey_del_cbind$SalePrice, y=(resid(model_AIC)^2)/nrow(rey_del_cbind))) +
  geom_point(colour="red")+
  stat_smooth(method='lm', se=F, color='black')+
  ggtitle('sqrt(y)가정')

p_resid2=ggplot(model_AIC, aes(x=rey_del_cbind$SalePrice, y=(resid(model_AIC)-mean(resid(model_AIC)))/nrow(rey_del_cbind))) +
  geom_point(colour="blue")+
  stat_smooth(method='lm', se=F, color='black')+
  ggtitle('log(y) 가정')

p_resid3=ggplot(model_AIC, aes(x=(rey_del_cbind$SalePrice)^2, y=(resid(model_AIC)-mean(resid(model_AIC)))/nrow(rey_del_cbind))) +
  geom_point(colour="brown")+
  stat_smooth(method='lm', se=F, color='black')+
  ggtitle('1/Y가정')

grid.arrange(p_resid1, p_resid2, p_resid3, ncol=3)

```


> 해당 그래프를 살펴보면 $\log(Y)$ 변환과 $1/Y$변환의 경우 별로 올바르지 못한것으로 보인다. 따라서 $\sqrt{Y}$변환이 가장 올바른것으로 판단된다. 하지만 $\log(Y)$ 변환과 $1/Y$변환 모두 진행해 보겠다. 


#### 2.4.A $\sqrt{Y}$변환
```{r}
rey_del_cbind1=rey_del_cbind
sqrt_sale=sqrt(rey_del_cbind1$SalePrice)
rey_del_cbind1$SalePrice=sqrt_sale
start.model=lm(data=rey_del_cbind1, SalePrice~Area)
stepAIC(start.model, scope=list(upper=~Area+year2+Days+Interior+Condo+Tax+RC+Bed+Bath+Rooms, lower=~Area), direction='both')
rey_del_model_sqrt=lm(data=rey_del_cbind1, SalePrice~Area + Tax + Interior + Condo + year2 + Days + Rooms)

p1 = ggplot(rey_del_model_sqrt, aes(resid(rey_del_model_sqrt), y=..density..)) +     geom_histogram(fill='blue', colour='white')+
  geom_density(fill=NA, colour=NA)+
  geom_line(stat="density")+
  ggtitle('Histogram + Kernal Density Curve Residual')

p2 = ggplot(rey_del_model_sqrt, aes(x=predict(rey_del_model_sqrt), y=resid(rey_del_model_sqrt))) +
  geom_point(colour="red")+
  ggtitle('Scatter plot Residuals')
p3 = ggplot(rey_del_model_sqrt, aes(sample=resid(rey_del_model_sqrt))) + 
  stat_qq()
  
grid.arrange(p1, p3, p2, ncol=3)

shapiro.test(resid(rey_del_model_sqrt))
library(car)
ncvTest(rey_del_model_sqrt)

```
> `정상성`과 `등분상성` 모두 충족시키지 못한다. 추가적으로 $\log(Y)$변환 또한 살펴보겠다.

#### 2.4.B $\log(Y)$ 변환

```{r}
rey_del_cbind2=rey_del_cbind
log_sale=log(rey_del_cbind2$SalePrice)
rey_del_cbind2$SalePrice=log_sale
start.model=lm(data=rey_del_cbind2, SalePrice~Area)
stepAIC(start.model, scope=list(upper=~Area+year2+Days+Interior+Condo+Tax+RC+Bed+Bath+Rooms, lower=~Area), direction='both')
rey_del_model_log=lm(data=rey_del_cbind2, SalePrice~Area + Tax + Interior + Condo + Days + year2 + Rooms)

p1 = ggplot(rey_del_model_log, aes(resid(rey_del_model_log), y=..density..)) +     geom_histogram(fill='blue', colour='white')+
  geom_density(fill=NA, colour=NA)+
  geom_line(stat="density")+
  ggtitle('Histogram + Kernal Density Curve Residual')

p2 = ggplot(rey_del_model_log, aes(x=predict(rey_del_model_log), y=resid(rey_del_model_log))) +
  geom_point(colour="red")+
  ggtitle('Scatter plot Residuals')
p3 = ggplot(rey_del_model_log, aes(sample=resid(rey_del_model_log))) + 
  stat_qq()
  
grid.arrange(p1, p3, p2, ncol=3)

shapiro.test(resid(rey_del_model_log))
library(car)
ncvTest(rey_del_model_log)
spreadLevelPlot(rey_del_model_log)

```
> 결과 : $\log(Y)$변환을 실시한 후 `이분산 테스트`가 `0.05644`로 `등분산성`을 `만족`하는것을 볼 수 있다. 추가적으로 다음은 $1/Y$변환을 통해 살펴보겠다. 

#### 2.4.C $1/Y$변환

```{r}
rey_del_cbind3=rey_del_cbind
div_sale=1/rey_del_cbind$SalePrice
rey_del_cbind3$SalePrice=div_sale
start.model=lm(data=rey_del_cbind3, SalePrice~Area)
stepAIC(start.model, scope=list(upper=~Area+year2+Days+Interior+Condo+Tax+RC+Bed+Bath+Rooms, lower=~Area), direction='both')
rey_del_model_div=lm(data=rey_del_cbind3, SalePrice~Area + Interior + Tax + Days + Rooms + Condo + year2 + RC)

p1 = ggplot(rey_del_model_div, aes(resid(rey_del_model_div), y=..density..)) +     geom_histogram(fill='blue', colour='white')+
  geom_density(fill=NA, colour=NA)+
  geom_line(stat="density")+
  ggtitle('Histogram + Kernal Density Curve Residual')

p2 = ggplot(rey_del_model_div, aes(x=predict(rey_del_model_div), y=resid(rey_del_model_div))) +
  geom_point(colour="red")+
  ggtitle('Scatter plot Residuals')
p3 = ggplot(rey_del_model_div, aes(sample=resid(rey_del_model_div))) + 
  stat_qq()
  
grid.arrange(p1, p3, p2, ncol=3)

shapiro.test(resid(rey_del_model_div))
library(car)
ncvTest(rey_del_model_div)

```
> 결과 : $1/Y$변환의 경우 분산의 `정규성가정`은 통과하지 못했고 `등분산가정` 또한 통과하지 못했다. 따라서 $\log(Y)$ 데이터만을 고려하여 분석을 진행하겠다. 

#### 2.5 이상치 테스트
#### $\log(Y)$ 변환데이터를 기준으로` Cock's distance`를 활용하여 `outlier`들을 삭제한 후 분석을 추가로 진행하겠다. 

```{r}

cooksd_log <- cooks.distance(rey_del_model_log)
plot(cooksd_log, pch="*", cex=2, main='coocks distance outlier test')
abline(h=4*mean(cooksd_log, na.rm=T), col="red")
text(x=1:length(cooksd_log)+1, y=cooksd_log, labels=ifelse(cooksd_log>4*mean(cooksd_log, na.rm=T), names(cooksd_log), ""), col="red")
```


> 해당 그래프에 따르면 굉장히 많은 outlier들이 관찰되는것을 알 수있다. 

#### 2.6 다음은 `Leverage Test`를 진행하겠다.


```{r}
k = length(rey_del_model_log$coefficients)
n = length(rey_del_cbind2)
leverage_point=3*sqrt((25+1)/(456-25-1))
leveragePlots(rey_del_model_log)

```

#### 2.7 관측된 `Leverage와 Outlier`를 제거하겠다. 

```{r}
library(Rfit)
names(rey_del_cbind)
outlier = cbind(subset(rey_del_cbind2, abs(rstudent(rey_del_model_log))>=3), subset(rstudent(rey_del_model_log), abs(rstudent(rey_del_model_log))>=3))
outlier

clear_outlier=cbind(subset(rey_del_cbind2, abs(rstudent(rey_del_model_log))<=3), subset(rstudent(rey_del_model_log), abs(rstudent(rey_del_model_log))<=3))

leverage = cbind(subset(rey_del_cbind2, abs(dffits(rey_del_model_log))>=leverage_point), subset(dffits(rey_del_model_log), abs(dffits(rey_del_model_log))>=leverage_point))
leverage

clear_outlier_leverage=cbind(subset(clear_outlier, abs(dffits(rey_del_model_log))<=leverage_point),
subset(dffits(rey_del_model_log),
abs(dffits(rey_del_model_log))<=leverage_point))
dim(rey_del_cbind2)
dim(clear_outlier_leverage)

```
> `outlier`는 총 `11`개가 제거되었으며 제거한 데이터를 기준으로 다시 분석을 실시 하였다. 

#### 3. FInal Model
```{r}
start.model = lm(data=clear_outlier_leverage, SalePrice ~ Area)
stepAIC(start.model, scope=list(upper=~Area+year2+Days+Interior+Condo+Tax+RC+Bed+Bath+Rooms, lower=~Area), direction='both')
```
> 모델이 수정되어 `SalePrice ~ Area + Interior + Tax + year2 + Condo + Days` 모델이 가장 AIC값이 낮게 나온다. 


#### 3.1 Residual Test


#### 수정된 모델의 잔차분석결과는 다음과 같다. 

```{r}
Final_model=lm(data=clear_outlier_leverage, SalePrice ~ Area + Interior + Tax + year2 + Condo + Days)

p1 = ggplot(Final_model, aes(resid(Final_model), y=..density..)) +     geom_histogram(fill='blue', colour='white')+
  geom_density(fill=NA, colour=NA)+
  geom_line(stat="density")+
  ggtitle('Histogram + Kernal Density Curve Residual')

p2 = ggplot(Final_model, aes(x=predict(Final_model), y=resid(Final_model))) +
  geom_point(colour="red")+
  ggtitle('Scatter plot Residuals')
p3 = ggplot(Final_model, aes(sample=resid(Final_model))) + 
  stat_qq()
  
grid.arrange(p1, p3, p2, ncol=3)

shapiro.test(resid(Final_model))
library(car)
ncvTest(Final_model)
```
> `Breusch-Pegan Test`결과 `P-Value`는  `0.60537` 로 `대립가설`을 `기각`하여 `등분산성`을 보인다. 따라서 최종 모델은
 
$Log(SalesPrice)= Area + Year + Interior + Tax + Condo + Days$|
```{r}
summary(Final_model)
reyeme = data.frame(Area='M', year2='1994', Interior = 1040, Tax = 1121, Condo = 175, Days = 23)
reyeme_house = predict(Final_model, newdata=reyeme, interval='confidence')
exp(reyeme_house)
```
> 최종 결과는 다음과 같다

Lower|Fit|Upper
---|---|---
__145040__|**154474**|**164522**
> 따라서 `reyeme`는 주택을 구매할 경우 위 가격을 고려하여 의사결정을 실시해야한다. 